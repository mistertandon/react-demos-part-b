{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN\n",
    "\n",
    "In ths notebook, we're going to train a simple RNN to do **time-series prediction**. Given some set of input data, it should be able to generate a prediction for the next time step!\n",
    "<img src='assets/time_prediction.png' width=40% />\n",
    "\n",
    "> * First, we'll create our data\n",
    "* Then, define an RNN in PyTorch\n",
    "* Finally, we'll train our network and see how it performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import resources and create data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.15707963, 0.31415927, 0.4712389 , 0.62831853,\n",
       "       0.78539816, 0.9424778 , 1.09955743, 1.25663706, 1.41371669,\n",
       "       1.57079633, 1.72787596, 1.88495559, 2.04203522, 2.19911486,\n",
       "       2.35619449, 2.51327412, 2.67035376, 2.82743339, 2.98451302,\n",
       "       3.14159265])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many time steps/data pts are in one batch of data\n",
    "seq_length = 20\n",
    "\n",
    "# generate evenly spaced data pts\n",
    "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
    "time_steps.shape\n",
    "time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.56434465e-01, 3.09016994e-01, 4.53990500e-01,\n",
       "       5.87785252e-01, 7.07106781e-01, 8.09016994e-01, 8.91006524e-01,\n",
       "       9.51056516e-01, 9.87688341e-01, 1.00000000e+00, 9.87688341e-01,\n",
       "       9.51056516e-01, 8.91006524e-01, 8.09016994e-01, 7.07106781e-01,\n",
       "       5.87785252e-01, 4.53990500e-01, 3.09016994e-01, 1.56434465e-01,\n",
       "       1.22464680e-16])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.sin(time_steps)\n",
    "data.shape\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 1)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00],\n",
       "       [1.56434465e-01],\n",
       "       [3.09016994e-01],\n",
       "       [4.53990500e-01],\n",
       "       [5.87785252e-01],\n",
       "       [7.07106781e-01],\n",
       "       [8.09016994e-01],\n",
       "       [8.91006524e-01],\n",
       "       [9.51056516e-01],\n",
       "       [9.87688341e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.87688341e-01],\n",
       "       [9.51056516e-01],\n",
       "       [8.91006524e-01],\n",
       "       [8.09016994e-01],\n",
       "       [7.07106781e-01],\n",
       "       [5.87785252e-01],\n",
       "       [4.53990500e-01],\n",
       "       [3.09016994e-01],\n",
       "       [1.56434465e-01],\n",
       "       [1.22464680e-16]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
    "data.shape\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.15643447],\n",
       "       [0.30901699],\n",
       "       [0.4539905 ],\n",
       "       [0.58778525],\n",
       "       [0.70710678],\n",
       "       [0.80901699],\n",
       "       [0.89100652],\n",
       "       [0.95105652],\n",
       "       [0.98768834],\n",
       "       [1.        ],\n",
       "       [0.98768834],\n",
       "       [0.95105652],\n",
       "       [0.89100652],\n",
       "       [0.80901699],\n",
       "       [0.70710678],\n",
       "       [0.58778525],\n",
       "       [0.4539905 ],\n",
       "       [0.30901699],\n",
       "       [0.15643447]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data[:-1] # all but the last piece of data\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.56434465e-01],\n",
       "       [3.09016994e-01],\n",
       "       [4.53990500e-01],\n",
       "       [5.87785252e-01],\n",
       "       [7.07106781e-01],\n",
       "       [8.09016994e-01],\n",
       "       [8.91006524e-01],\n",
       "       [9.51056516e-01],\n",
       "       [9.87688341e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.87688341e-01],\n",
       "       [9.51056516e-01],\n",
       "       [8.91006524e-01],\n",
       "       [8.09016994e-01],\n",
       "       [7.07106781e-01],\n",
       "       [5.87785252e-01],\n",
       "       [4.53990500e-01],\n",
       "       [3.09016994e-01],\n",
       "       [1.56434465e-01],\n",
       "       [1.22464680e-16]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[1:] # all but the first\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveShell.ast_node_interactivity = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# display the data\n",
    "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
    "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define the RNN\n",
    "\n",
    "Next, we define an RNN in PyTorch. We'll use `nn.RNN` to create an RNN layer, then we'll add a last, fully-connected layer to get the output size that we want. An RNN takes in a number of parameters:\n",
    "* **input_size** - the size of the input\n",
    "* **hidden_dim** - the number of features in the RNN output and in the hidden state\n",
    "* **n_layers** - the number of layers that make up the RNN, typically 1-3; greater than 1 means that you'll create a stacked RNN\n",
    "* **batch_first** - whether or not the input/output of the RNN will have the batch_size as the first dimension (batch_size, seq_length, hidden_dim)\n",
    "\n",
    "Take a look at the [RNN documentation](https://pytorch.org/docs/stable/nn.html#rnn) to read more about recurrent layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim=hidden_dim\n",
    "\n",
    "        # define an RNN with specified parameters\n",
    "        # batch_first means that the first dim of the input and output will be the batch_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        \n",
    "        # last, fully-connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # x (batch_size, seq_length, input_size)\n",
    "        # hidden (n_layers, batch_size, hidden_dim)\n",
    "        # r_out (batch_size, time_step, hidden_size)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # get RNN outputs\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "        '''\n",
    "        Uncomment to debug about layers dimensions\n",
    "        \n",
    "        print('Passed input_size : ', x.shape)\n",
    "        print('Passed hidden_size : ', self.hidden_dim)\n",
    "        print('hidden.shape', hidden.shape)\n",
    "        print('r_out.shape : Before view', r_out.shape)\n",
    "        '''\n",
    "        \n",
    "        # shape output to be (batch_size*seq_length, hidden_dim)\n",
    "        r_out = r_out.view(-1, self.hidden_dim)\n",
    "        \n",
    "        \n",
    "        # get final output \n",
    "        output = self.fc(r_out)\n",
    "        '''\n",
    "        Uncomment to debug about layers dimensions\n",
    "        \n",
    "        print('r_out.shape : After view', r_out.shape)\n",
    "        print('output.shape : ', output.shape)\n",
    "        '''\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the input and output dimensions\n",
    "\n",
    "As a check that your model is working as expected, test out how it responds to input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.16534698, 0.33069396, 0.49604095, 0.66138793,\n",
       "       0.82673491, 0.99208189, 1.15742887, 1.32277585, 1.48812284,\n",
       "       1.65346982, 1.8188168 , 1.98416378, 2.14951076, 2.31485774,\n",
       "       2.48020473, 2.64555171, 2.81089869, 2.97624567, 3.14159265])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate evenly spaced, test data pts\n",
    "time_steps = np.linspace(0, np.pi, seq_length)\n",
    "time_steps.shape\n",
    "time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.64594590e-01, 3.24699469e-01, 4.75947393e-01,\n",
       "       6.14212713e-01, 7.35723911e-01, 8.37166478e-01, 9.15773327e-01,\n",
       "       9.69400266e-01, 9.96584493e-01, 9.96584493e-01, 9.69400266e-01,\n",
       "       9.15773327e-01, 8.37166478e-01, 7.35723911e-01, 6.14212713e-01,\n",
       "       4.75947393e-01, 3.24699469e-01, 1.64594590e-01, 1.22464680e-16])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.sin(time_steps)\n",
    "data.shape\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00],\n",
       "       [1.64594590e-01],\n",
       "       [3.24699469e-01],\n",
       "       [4.75947393e-01],\n",
       "       [6.14212713e-01],\n",
       "       [7.35723911e-01],\n",
       "       [8.37166478e-01],\n",
       "       [9.15773327e-01],\n",
       "       [9.69400266e-01],\n",
       "       [9.96584493e-01],\n",
       "       [9.96584493e-01],\n",
       "       [9.69400266e-01],\n",
       "       [9.15773327e-01],\n",
       "       [8.37166478e-01],\n",
       "       [7.35723911e-01],\n",
       "       [6.14212713e-01],\n",
       "       [4.75947393e-01],\n",
       "       [3.24699469e-01],\n",
       "       [1.64594590e-01],\n",
       "       [1.22464680e-16]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.resize((seq_length, 1))\n",
    "data.shape\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00],\n",
       "        [1.6459e-01],\n",
       "        [3.2470e-01],\n",
       "        [4.7595e-01],\n",
       "        [6.1421e-01],\n",
       "        [7.3572e-01],\n",
       "        [8.3717e-01],\n",
       "        [9.1577e-01],\n",
       "        [9.6940e-01],\n",
       "        [9.9658e-01],\n",
       "        [9.9658e-01],\n",
       "        [9.6940e-01],\n",
       "        [9.1577e-01],\n",
       "        [8.3717e-01],\n",
       "        [7.3572e-01],\n",
       "        [6.1421e-01],\n",
       "        [4.7595e-01],\n",
       "        [3.2470e-01],\n",
       "        [1.6459e-01],\n",
       "        [1.2246e-16]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = torch.Tensor(data) # give it a batch_size of 1 as first dimension\n",
    "test_input.shape\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 1])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00],\n",
       "         [1.6459e-01],\n",
       "         [3.2470e-01],\n",
       "         [4.7595e-01],\n",
       "         [6.1421e-01],\n",
       "         [7.3572e-01],\n",
       "         [8.3717e-01],\n",
       "         [9.1577e-01],\n",
       "         [9.6940e-01],\n",
       "         [9.9658e-01],\n",
       "         [9.9658e-01],\n",
       "         [9.6940e-01],\n",
       "         [9.1577e-01],\n",
       "         [8.3717e-01],\n",
       "         [7.3572e-01],\n",
       "         [6.1421e-01],\n",
       "         [4.7595e-01],\n",
       "         [3.2470e-01],\n",
       "         [1.6459e-01],\n",
       "         [1.2246e-16]]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = test_input.unsqueeze(0) # give it a batch_size of 1 as first dimension\n",
    "test_input.shape\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): RNN(1, 10, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test that dimensions are as expected\n",
    "test_rnn = RNN(input_size=1, output_size=1, hidden_dim=10, n_layers=2)\n",
    "test_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size:  torch.Size([1, 20, 1])\n",
      "Output size:  torch.Size([20, 1])\n",
      "Hidden state size:  torch.Size([2, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "print('Input size: ', test_input.size())\n",
    "\n",
    "# test out rnn sizes\n",
    "test_out, test_h = test_rnn(test_input, None)\n",
    "print('Output size: ', test_out.size())\n",
    "print('Hidden state size: ', test_h.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training the RNN\n",
    "\n",
    "Next, we'll instantiate an RNN with some specified hyperparameters. Then train it over a series of steps, and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(1, 32, num_layers=3, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# decide on hyperparameters\n",
    "input_size=1\n",
    "output_size=1\n",
    "hidden_dim=32\n",
    "n_layers=3\n",
    "\n",
    "# instantiate an RNN\n",
    "rnn = RNN(input_size, output_size, hidden_dim, n_layers)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Optimization\n",
    "\n",
    "This is a regression problem: can we train an RNN to accurately predict the next data point, given a current data point?\n",
    "\n",
    ">* The data points are coordinate values, so to compare a predicted and ground_truth point, we'll use a regression loss: the mean squared error.\n",
    "* It's typical to use an Adam optimizer for recurrent models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss and Adam optimizer with a learning rate of 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the training function\n",
    "\n",
    "This function takes in an rnn, a number of steps to train for, and returns a trained rnn. This function is also responsible for displaying the loss and the predictions, every so often.\n",
    "\n",
    "#### Hidden State\n",
    "\n",
    "Pay close attention to the hidden state, here:\n",
    "* Before looping over a batch of training data, the hidden state is initialized\n",
    "* After a new hidden state is generated by the rnn, we get the latest hidden state, and use that as input to the rnn for the following steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the RNN\n",
    "def train(rnn, n_steps, print_every):\n",
    "    \n",
    "    # initialize the hidden state\n",
    "    hidden = None      \n",
    "    \n",
    "    for batch_i, step in enumerate(range(n_steps)):\n",
    "        # defining the training data \n",
    "        time_steps = np.linspace(step * np.pi, (step+1)*np.pi, seq_length + 1)\n",
    "        data = np.sin(time_steps)\n",
    "        data.resize((seq_length + 1, 1)) # input_size=1\n",
    "\n",
    "\n",
    "        x = data[:-1]\n",
    "        y = data[1:]\n",
    "        \n",
    "        # convert data into Tensors\n",
    "        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension\n",
    "        y_tensor = torch.Tensor(y)\n",
    "        # outputs from the rnn\n",
    "        prediction, hidden = rnn(x_tensor, hidden)\n",
    "\n",
    "        ## Representing Memory ##\n",
    "        # make a new variable for hidden and detach the hidden state from its history\n",
    "        # this way, we don't backpropagate through the entire history\n",
    "        hidden = hidden.data\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(prediction, y_tensor)\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # perform backprop and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # display loss and predictions\n",
    "        if batch_i%print_every == 0:        \n",
    "            print('Loss: ', loss.item())\n",
    "            plt.plot(time_steps[1:], x, 'r.') # input\n",
    "            plt.plot(time_steps[1:], prediction.data.numpy().flatten(), 'b.') # predictions\n",
    "            plt.show()\n",
    "    \n",
    "    return rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.4351322650909424\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the rnn and monitor results\n",
    "n_steps = 75\n",
    "print_every = 15\n",
    "\n",
    "trained_rnn = train(rnn, n_steps, print_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Series Prediction\n",
    "\n",
    "Time-series prediction can be applied to many tasks. Think about weather forecasting or predicting the ebb and flow of stock market prices. You can even try to generate predictions much further in the future than just one time step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
